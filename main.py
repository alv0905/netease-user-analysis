import streamlit as st
import pandas as pd
import numpy as np
# éœ€è¦ scikit-learn
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import io
import matplotlib.pyplot as plt
from matplotlib import font_manager

# è®¾ç½® matplotlib ä¸­æ–‡å­—ä½“
font_path = "E:/Netease_analysis/assets/SourceHanSansHWSC/OTF/SimplifiedChineseHW/SourceHanSansHWSC-Regular.otf"
font_prop = font_manager.FontProperties(fname=font_path)


def render():
    # ---------------------
    # ä½ çš„ç°æœ‰ä¸»é¡µå¸ƒå±€
    # ---------------------
    st.title("ğŸµ ç½‘æ˜“äº‘éŸ³ä¹ç”¨æˆ·è¡Œä¸ºåˆ†æå¹³å°")
    st.markdown("### ğŸ“Š å¹³å°åŠŸèƒ½æ¦‚è§ˆ")
    colA, colB = st.columns(2)

    with colA:
        st.subheader("ğŸ‘¤ ç”¨æˆ·ç”»åƒåˆ†æ")
        st.markdown("ç”¨æˆ·åŸºç¡€ä¿¡æ¯ã€åœ°åŒºã€æ€§åˆ«ã€ç­‰çº§ç­‰")
        st.subheader("ğŸ¶ æ­Œå•åå¥½åˆ†æ")
        st.markdown("æ­Œå•åˆ›å»ºã€æ”¶è—ã€æ¨èç®—æ³•ç­‰")

    with colB:
        st.subheader("ğŸ¼ æ’­æ”¾è¡Œä¸ºåˆ†æ")
        st.markdown("æ’­æ”¾è®°å½•ã€çƒ­é—¨æ­Œæ›²ã€è¯„åˆ†è¶‹åŠ¿ç­‰")
        st.subheader("ğŸ’¬ ç¤¾äº¤äº’åŠ¨åˆ†æ")
        st.markdown("ç²‰ä¸æ•°ã€å…³æ³¨è¡Œä¸ºã€ç¤¾åŒºäº’åŠ¨ç­‰")

    st.markdown("### ğŸŒŸ å¹³å°äº®ç‚¹")
    st.success("âœ… æ•°æ®æ¥è‡ªçœŸå®ç½‘æ˜“äº‘ç”¨æˆ·ï¼Œä¿è¯åˆ†æçš„çœŸå®æ€§")
    st.success("âœ… å¤šç»´åº¦åˆ†æï¼Œæ¶µç›–æ’­æ”¾ã€ç¤¾äº¤ã€æ­Œå•è¡Œä¸ºç­‰")
    st.success("âœ… äº¤äº’å¼ç½‘é¡µå¹³å°ï¼Œæ‰€æœ‰å›¾è¡¨å‡å¯å®æ—¶å±•ç¤º")

    st.markdown("### ğŸ§­ å¦‚ä½•ä½¿ç”¨æœ¬å¹³å°")
    st.markdown(
        "1. ğŸ‘‰ ç‚¹å‡»é¡¶éƒ¨èœå•åˆ‡æ¢åˆ†ææ¨¡å—  \n"
        "2. ğŸ“ˆ æŸ¥çœ‹äº¤äº’å›¾è¡¨ä¸åˆ†ææ•°æ®  \n"
        "3. ğŸ“ å›¾è¡¨å¯å¯¼å‡ºä¿å­˜ï¼Œç”¨äºæŠ¥å‘Šæˆ–ç ”ç©¶  \n"
    )
    st.info("ğŸ“Œ æç¤ºï¼šç‚¹å‡»é¡¶éƒ¨èœå•æ é€‰æ‹©ä½ æƒ³æŸ¥çœ‹çš„åˆ†ææ¨¡å—ã€‚")

    # ---------------------
    # æ–°å¢ï¼šç»¼åˆå››å¼ è¡¨çš„èšç±»å¯è§†åŒ–
    # ---------------------
    st.markdown("---")
    st.markdown("## ğŸ¨ ç”¨æˆ·èšç±»åˆ†å¸ƒ")

    merged_df = load_and_merge_data()
    if merged_df.empty:
        st.warning("â“ æœªè·å–åˆ°åˆå¹¶åçš„ç”¨æˆ·æ•°æ®ï¼Œå¯èƒ½ CSV è·¯å¾„ä¸æ­£ç¡®æˆ–æ–‡ä»¶ä¸ºç©ºã€‚")
        return

    # é€‰æ‹© K å€¼
    n_clusters = st.slider("é€‰æ‹©èšç±»ä¸ªæ•° (K)", min_value=2, max_value=6, value=3, step=1)

    fig, labels = cluster_and_visualize(merged_df, n_clusters=n_clusters)
    st.pyplot(fig)

    st.caption("æ­¤å›¾ä½¿ç”¨K-meansç®—æ³• + PCAé™ç»´ã€‚é¢œè‰²=èšç±»åˆ†ç»„ï¼Œä»…ä¾›å‚è€ƒã€‚")

    # âœ… æ–°å¢ï¼šå±•ç¤ºå„èšç±»åœ¨åŸå§‹ç‰¹å¾ä¸Šçš„å‡å€¼è¡¨
    cluster_summary_df = interpret_clusters(merged_df, labels)
    st.markdown("### å„èšç±»å¹³å‡ç‰¹å¾å€¼")
    st.dataframe(cluster_summary_df)

    st.info("""
        é€šè¿‡ä¸Šè¡¨å¯ä»¥çœ‹å‡ºæ¯ä¸ªèšç±»åœ¨ [level, total_plays, total_playlists, fans_count, follows_count]
        ç­‰æŒ‡æ ‡ä¸Šçš„å‡å€¼ã€‚ç»“åˆæ•£ç‚¹å›¾é¢œè‰²ï¼Œä½ å¯ä»¥è½»æ¾å¾—å‡ºï¼š
        - å“ªä¸ªèšç±»ç­‰çº§æœ€é«˜ï¼Ÿ
        - å“ªä¸ªèšç±»ç²‰ä¸æ•°æœ€å¤šï¼Ÿ
        - å“ªä¸ªèšç±»æ’­æ”¾é‡æœ€å¤šï¼Ÿ
        ç­‰ç»“è®ºã€‚
        """)


def load_and_merge_data():
    # è·¯å¾„å‚è€ƒ
    try:
        basic = pd.read_csv("E:/Netease_analysis/data/basic_info.csv")
        listen = pd.read_csv("E:/Netease_analysis/data/listening_records.csv")
        playlist = pd.read_csv("E:/Netease_analysis/data/playlist_info.csv")
        social = pd.read_csv("E:/Netease_analysis/data/social_info.csv")
    except Exception as e:
        st.error(f"è¯»å–CSVå‡ºé”™: {e}")
        return pd.DataFrame()

    listen_agg = listen.groupby("user_id", as_index=False)["playCount"].sum()
    listen_agg.rename(columns={"playCount": "total_plays"}, inplace=True)

    merged = pd.merge(basic[["user_id", "level"]], listen_agg, on="user_id", how="left")
    merged = pd.merge(merged, playlist[["user_id", "total_playlists"]], on="user_id", how="left")
    merged = pd.merge(merged, social[["user_id", "fans_count", "follows_count"]], on="user_id", how="left")

    for col in ["total_plays", "total_playlists", "fans_count", "follows_count", "level"]:
        merged[col] = merged[col].fillna(0)

    return merged


def cluster_and_visualize(merged_df, n_clusters=3):
    X = merged_df[["level", "total_plays", "total_playlists", "fans_count", "follows_count"]].values

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X)

    pca = PCA(n_components=2, random_state=42)
    X_pca = pca.fit_transform(X)

    fig, ax = plt.subplots(figsize=(8, 6))
    scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap="rainbow", alpha=0.7)
    ax.set_xlabel("PCA-1")
    ax.set_ylabel("PCA-2")
    ax.set_title(f"ç”¨æˆ·èšç±»ç»“æœ (K={n_clusters})", fontproperties=font_prop)


    return fig, labels


def interpret_clusters(merged_df, labels):
    """
    æ ¹æ®èšç±»ç»“æœ labelsï¼Œå¯¹ merged_df çš„ [level, total_plays, ...] åš groupby å¹³å‡å€¼ã€‚
    è¿”å›ä¸€ä¸ª DataFrameï¼š
        cluster | level | total_plays | total_playlists | fans_count | follows_count | user_count
    """
    # æŠŠ labels å†™å› merged_df
    temp_df = merged_df.copy()
    temp_df["cluster"] = labels

    # groupby è®¡ç®—å‡å€¼
    # æ³¨æ„ï¼šuser_count ç»Ÿè®¡å„ç°‡äººæ•°
    group_mean = temp_df.groupby("cluster", as_index=False).agg({
        "user_id": "count",
        "level": "mean",
        "total_plays": "mean",
        "total_playlists": "mean",
        "fans_count": "mean",
        "follows_count": "mean"
    }).rename(columns={"user_id": "user_count"})

    # ç¾åŒ–æ•°å€¼
    # group_mean = group_mean.round(2)  # è‹¥ä½ æƒ³ä¿ç•™ä¸¤ä½å°æ•°

    # è®© cluster åˆ—æ”¾åœ¨æœ€å·¦è¾¹
    columns_order = ["cluster", "user_count", "level", "total_plays", "total_playlists", "fans_count", "follows_count"]
    group_mean = group_mean[columns_order]

    return group_mean
